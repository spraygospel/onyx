# 1.1 Built-in LLM Integration - Todo List

Development task breakdown for extensible LLM provider architecture implementation.

## 📋 Phase 0: Test-First Development (FAANG TDD Methodology)

**Following CLAUDE.md TDD principles: Write tests FIRST, then implement code**

### Backend Test Scripts (Create BEFORE Implementation)
- [ ] **Provider Template Tests**
  - Location: `tests/unit/backend/llm/test_provider_templates.py`
  - Test: ProviderTemplate validation, schema validation, required fields
  - Test: Provider category classification and difficulty levels
  - Test: LiteLLM provider name mapping validation

- [ ] **Model Fetcher Tests** 
  - Location: `tests/unit/backend/llm/test_model_fetcher.py`
  - Test: Dynamic API fetching for each provider (mocked)
  - Test: TTL caching behavior and cache invalidation
  - Test: Fallback to static models when API fails
  - Test: Error handling for network timeouts and invalid responses

- [ ] **Provider API Integration Tests**
  - Location: `tests/integration/backend/llm/test_provider_apis.py`
  - Test: Real API calls to Groq, Together AI, Fireworks AI (with test API keys)
  - Test: Ollama local server integration (with test server)
  - Test: Model list parsing for each provider format
  - Test: Authentication and rate limiting handling

- [ ] **LLM Provider Options Tests**
  - Location: `tests/unit/backend/llm/test_llm_provider_options.py`
  - Test: Updated `fetch_available_well_known_llms()` with new providers
  - Test: Backward compatibility with existing 5 providers
  - Test: Provider template integration with existing interfaces

- [ ] **API Endpoint Tests**
  - Location: `tests/integration/backend/api/test_llm_provider_management.py`
  - Test: `GET /api/admin/llm/providers/{provider_id}/models` endpoint
  - Test: `POST /api/admin/llm/providers/{provider_id}/refresh-models` endpoint
  - Test: Error responses and status codes
  - Test: Authentication and authorization for admin endpoints

### Frontend Test Scripts (Create BEFORE Implementation)
- [ ] **Provider Template Interface Tests**
  - Location: `tests/unit/frontend/llm/interfaces.test.ts`
  - Test: TypeScript interface validation for ProviderTemplate
  - Test: Config schema field types and validation
  - Test: Model fetching configuration options

- [ ] **Provider Card Component Tests**
  - Location: `tests/unit/frontend/components/ProviderCard.test.tsx`
  - Test: Rendering with different provider configurations
  - Test: Category badge display and setup difficulty indicators
  - Test: Click handlers and provider selection
  - Test: Loading and error states

- [ ] **Dynamic Form Generator Tests**
  - Location: `tests/unit/frontend/components/DynamicForm.test.tsx`
  - Test: Form generation from provider config_schema
  - Test: Different field types (text, password, url, select, file)
  - Test: Form validation and error messages
  - Test: Real-time validation and help text display

- [ ] **Model Discovery Component Tests**
  - Location: `tests/unit/frontend/components/ModelDiscovery.test.tsx`
  - Test: API-based model fetching with loading states
  - Test: Fallback to static models on API failure
  - Test: Manual model input and validation
  - Test: Model caching and refresh functionality

- [ ] **Configuration Wizard Tests**
  - Location: `tests/unit/frontend/components/ConfigWizard.test.tsx`
  - Test: 4-step wizard navigation and state management
  - Test: Provider selection, configuration, model selection, testing
  - Test: Form data persistence across steps
  - Test: Error handling and validation at each step

### End-to-End Test Scripts (Create BEFORE Implementation)
- [ ] **Complete Provider Setup E2E Tests**
  - Location: `tests/e2e/llm_provider_setup.spec.ts`
  - Test: Complete Ollama provider setup workflow
  - Test: Complete Groq provider setup workflow
  - Test: Complete Together AI provider setup workflow
  - Test: Complete Fireworks AI provider setup workflow
  - Test: Error scenarios and recovery

- [ ] **Provider Management E2E Tests**
  - Location: `tests/e2e/llm_provider_management.spec.ts`
  - Test: Provider listing and categorization
  - Test: Search and filter functionality
  - Test: Provider editing and deletion
  - Test: Custom integration preservation

- [ ] **Model Selection E2E Tests**
  - Location: `tests/e2e/llm_model_selection.spec.ts`
  - Test: Dynamic model fetching in browser
  - Test: Model selection and default model setup
  - Test: Model availability validation
  - Test: Fallback model behavior

### Performance Test Scripts (Create BEFORE Implementation)
- [ ] **API Performance Tests**
  - Location: `tests/performance/backend/api_performance.test.py`
  - Test: Model fetching response times (<5 seconds)
  - Test: Concurrent API calls handling
  - Test: Cache performance and hit rates (>80%)
  - Test: Memory usage during model fetching

- [ ] **Frontend Performance Tests**
  - Location: `tests/performance/frontend/ui_performance.spec.ts`
  - Test: Provider list rendering (<2 seconds)
  - Test: Dynamic form generation (<1 second)
  - Test: Search and filter responsiveness (<500ms)
  - Test: Configuration wizard flow performance

### Test Data and Fixtures (Create BEFORE Implementation)
- [ ] **Mock Provider Templates**
  - Location: `tests/fixtures/provider_templates.json`
  - Mock data for Groq, Ollama, Together AI, Fireworks AI
  - Mock API responses for model fetching
  - Test configuration schemas and field validation

- [ ] **Mock API Responses**
  - Location: `tests/fixtures/api_responses/`
  - Mock Groq API model list response
  - Mock Together AI API model list response  
  - Mock Fireworks AI API model list response
  - Mock Ollama `/api/tags` response

- [ ] **Test Environment Setup**
  - Location: `tests/setup/test_llm_providers.py`
  - Test database setup with provider configurations
  - Mock external API services for consistent testing
  - Test user permissions and authentication

## 📋 Phase 1: Core Infrastructure Implementation (After Tests)

### Backend Architecture
- [ ] **Create ProviderTemplate Interface** 
  - Define TypeScript interfaces for extensible provider configuration
  - Location: `backend/onyx/llm/provider_templates.py`
  - Include: id, name, description, category, config_schema, model_fetching, etc.

- [ ] **Implement Dynamic Model Fetcher**
  - Create ModelFetcher class with dynamic API fetching
  - Location: `backend/onyx/llm/model_fetcher.py`
  - Features: API fetching, TTL caching, fallback to static models
  - Support for different provider API formats

- [ ] **Add New API Endpoints**
  - `GET /api/admin/llm/providers/{provider_id}/models`
  - `POST /api/admin/llm/providers/{provider_id}/refresh-models`
  - Location: `backend/onyx/server/manage/llm/` 
  - Integration with existing LLM management APIs

- [ ] **Update Provider Registry System**
  - Modify `fetch_available_well_known_llms()` to use templates
  - Location: `backend/onyx/llm/llm_provider_options.py`
  - Maintain backward compatibility with existing 5 providers

### Frontend Architecture
- [ ] **Create Provider Template Types**
  - Define TypeScript interfaces matching backend templates
  - Location: `web/src/app/admin/configuration/llm/interfaces.ts`
  - Include all configuration schemas and validation types

- [ ] **Build Provider Card Component**
  - Visual provider cards with logo, difficulty, setup preview
  - Location: `web/src/app/admin/configuration/llm/components/ProviderCard.tsx`
  - Features: category badges, setup difficulty indicators, provider logos

- [ ] **Create Dynamic Form Generator**
  - Generate forms automatically from provider template config_schema
  - Location: `web/src/app/admin/configuration/llm/components/DynamicForm.tsx`
  - Support: text, password, url, select, file, textarea field types

- [ ] **Implement Model Discovery Component**
  - Real-time model fetching with loading states
  - Location: `web/src/app/admin/configuration/llm/components/ModelDiscovery.tsx`
  - Features: API fetching, fallback models, manual input, validation

## 📋 Phase 2: Priority Provider Integration

### Ollama Integration (70% Complete)
- [ ] **Complete Ollama Provider Definition**
  - Add OLLAMA_PROVIDER_NAME and template to `llm_provider_options.py`
  - Define popular models: llama3.2, qwen2.5, deepseek-coder, mistral-nemo
  - Configure dynamic model fetching via `/api/tags` endpoint

- [ ] **Test Ollama Dynamic Model Fetching**
  - Verify `/api/tags` endpoint parsing
  - Test fallback to static models when server unavailable
  - Validate 5-minute cache TTL for local server changes

### Groq Integration (Full Implementation)
- [ ] **Add Groq Provider Definition**
  - Create GROQ_PROVIDER_NAME and template
  - Configure dynamic model fetching via Groq API
  - Set up 1-hour cache TTL for cloud provider

- [ ] **Implement Groq API Integration**
  - Model fetching from `https://api.groq.com/openai/v1/models`
  - Parse response format and extract model names
  - Handle authentication with API key validation

- [ ] **Test Groq Integration**
  - Verify API connectivity and model parsing
  - Test fallback models: llama-3.1-8b-instant, llama-3.1-70b-versatile, etc.
  - Validate real-time model availability

### Together AI Integration (Full Implementation)  
- [ ] **Add Together AI Provider Definition**
  - Create TOGETHER_PROVIDER_NAME and template
  - Configure dynamic model fetching via Together API
  - Set up 1-hour cache TTL for cloud provider

- [ ] **Implement Together AI API Integration**
  - Model fetching from `https://api.together.xyz/v1/models`
  - Parse Together-specific response format
  - Handle API key authentication and rate limiting

- [ ] **Test Together AI Integration**
  - Verify API connectivity and model parsing
  - Test fallback models: Meta-Llama-3.1-8B-Instruct-Turbo, etc.
  - Validate model name formatting

### Fireworks AI Integration (Full Implementation)
- [ ] **Add Fireworks AI Provider Definition**
  - Create FIREWORKS_PROVIDER_NAME and template
  - Configure dynamic model fetching via Fireworks API
  - Set up 1-hour cache TTL for cloud provider

- [ ] **Implement Fireworks AI API Integration**
  - Model fetching from `https://api.fireworks.ai/inference/v1/models`
  - Parse Fireworks-specific response format
  - Handle API key authentication and error handling

- [ ] **Test Fireworks AI Integration**
  - Verify API connectivity and model parsing
  - Test fallback models: llama-v3p1-8b-instruct, etc.
  - Validate enterprise-grade reliability

## 📋 Phase 3: Enhanced User Experience

### Smart Configuration Wizard
- [ ] **Create 4-Step Configuration Wizard**
  - Step 1: Provider Selection (categories, search, recommendations)
  - Step 2: Basic Configuration (dynamic form generation)
  - Step 3: Model Selection (dynamic fetching, fallback, manual input)
  - Step 4: Test Connection (validation, error handling)

- [ ] **Implement Provider Categorization**
  - Popular Cloud: OpenAI, Anthropic, Groq, Together AI, Fireworks AI
  - Enterprise: Azure OpenAI, AWS Bedrock, GCP Vertex AI
  - Local/Self-hosted: Ollama, LM Studio, LocalAI
  - Custom Integration: Manual LiteLLM provider configuration

- [ ] **Add Search and Filter Functionality**
  - Provider search by name and description
  - Category filtering with visual indicators
  - Setup difficulty filtering (easy/medium/hard)
  - Provider recommendation engine

### Error Handling and Validation
- [ ] **Implement Comprehensive Error Handling**
  - API timeout handling with graceful fallbacks
  - Network error recovery with retry logic
  - Invalid API key detection and user feedback
  - Model availability validation

- [ ] **Add Real-time Validation**
  - API key format validation
  - Connection testing during setup
  - Model availability verification
  - Configuration completeness checking

- [ ] **Create Loading and Status Components**
  - Loading states for API calls
  - Progress indicators for multi-step processes
  - Status messages for success/error feedback
  - Retry mechanisms for failed operations

## 📋 Phase 4: Future Extensibility

### Custom Integration Preservation
- [ ] **Maintain Existing Custom LLM Provider Feature**
  - Ensure CustomLLMProviderUpdateForm remains functional
  - Test integration with new provider template system
  - Validate backward compatibility with existing setups

- [ ] **Enhance Custom Integration Experience**
  - Improve form validation for manual configurations
  - Add LiteLLM provider documentation links
  - Include configuration examples and templates
  - Support for future LiteLLM provider additions

### Monitoring and Health Checks
- [ ] **Implement Provider Health Monitoring**
  - Connection status tracking
  - Model availability monitoring
  - Performance metrics collection
  - Alert system for provider issues

- [ ] **Add Provider Analytics**
  - Usage statistics per provider
  - Model performance metrics
  - Error rate tracking
  - User preference analytics

### Enterprise Features
- [ ] **Bulk Provider Setup**
  - Import/export provider configurations
  - Batch provider configuration
  - Template-based setup for common use cases
  - Enterprise compliance validation

- [ ] **Advanced Configuration Management**
  - Provider configuration versioning
  - Rollback capabilities for failed updates
  - Configuration approval workflows
  - Audit logging for configuration changes

## 📋 Testing and Quality Assurance

### Unit Testing
- [ ] **Backend Unit Tests**
  - Provider template validation tests
  - Model fetcher functionality tests
  - API endpoint response tests
  - Error handling and fallback tests

- [ ] **Frontend Unit Tests**
  - Provider card component tests
  - Dynamic form generation tests
  - Model discovery component tests
  - Configuration wizard flow tests

### Integration Testing
- [ ] **Provider Integration Tests**
  - Test actual API calls to each provider
  - Verify model fetching and parsing
  - Test fallback mechanisms
  - Validate caching behavior

- [ ] **End-to-End Testing**
  - Complete provider setup workflows
  - Configuration wizard testing
  - Model selection and validation
  - Error scenario testing

### Performance Testing
- [ ] **API Performance Tests**
  - Model fetching response times
  - Cache performance validation
  - Concurrent API call handling
  - Memory usage optimization

- [ ] **UI Performance Tests**
  - Provider list rendering performance
  - Dynamic form generation speed
  - Model discovery loading times
  - Search and filter responsiveness

## 📋 Documentation and Deployment

### Technical Documentation
- [ ] **Update API Documentation**
  - Document new endpoints and parameters
  - Include provider template schema
  - Add model fetching API examples
  - Update authentication requirements

- [ ] **Create Developer Guide**
  - How to add new provider templates
  - Model fetching implementation guide
  - Custom integration best practices
  - Troubleshooting and debugging guide

### User Documentation  
- [ ] **Update Configuration Guides**
  - Step-by-step provider setup instructions
  - Troubleshooting common issues
  - Model selection recommendations
  - Performance optimization tips

- [ ] **Create Provider-Specific Guides**
  - Ollama local setup guide
  - Groq API key setup and usage
  - Together AI configuration guide
  - Fireworks AI enterprise setup

### Deployment Preparation
- [ ] **Database Migration Scripts**
  - Provider template storage schema
  - Model cache table creation
  - Configuration versioning support
  - Data migration from old format

- [ ] **Configuration Management**
  - Environment variable updates
  - Feature flag configuration
  - Cache configuration settings
  - Monitoring and logging setup

## 📊 Success Criteria

### Functional Requirements
- [ ] **All 4 Priority Providers Working**
  - Ollama, Groq, Together AI, Fireworks AI fully functional
  - Dynamic model fetching operational
  - Fallback mechanisms tested and working

- [ ] **Custom Integration Preserved**
  - Existing custom LLM provider feature maintained
  - Backward compatibility with current configurations
  - Support for manual LiteLLM provider addition

- [ ] **User Experience Improved**
  - Configuration wizard reduces setup time by >50%
  - Provider discovery and categorization functional
  - Error handling provides clear user feedback

### Performance Requirements
- [ ] **API Performance Targets**
  - Model fetching: <5 seconds per provider
  - Cache hit rate: >80% for model lists
  - Configuration wizard: <30 seconds total time

- [ ] **UI Performance Targets**
  - Provider list rendering: <2 seconds
  - Dynamic form generation: <1 second
  - Search and filter: <500ms response time

### Quality Requirements
- [ ] **Test Coverage**
  - Unit tests: >80% code coverage
  - Integration tests: All provider APIs tested
  - E2E tests: Complete user workflows covered

- [ ] **Error Handling**
  - Graceful degradation for API failures
  - Clear error messages for users
  - Automatic retry mechanisms where appropriate

- [ ] **Documentation**
  - Complete API documentation
  - User setup guides for all providers
  - Developer integration examples

---

## 📝 Notes

**Estimated Timeline**: 3-4 weeks for complete implementation
**Priority Order**: Phase 0 (Tests First) → Phase 1 → Phase 2 → Phase 3 → Phase 4
**Dependencies**: Tests must be written FIRST (TDD), then backend infrastructure, then frontend components
**Risk Factors**: Provider API changes, rate limiting, authentication issues

**Team Coordination**: 
- Backend tasks can run in parallel with UI design
- Integration testing requires all providers to be implemented
- Documentation should be updated incrementally during development